{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "42e285cb",
      "metadata": {
        "id": "42e285cb"
      },
      "source": [
        "**Text Classification using BERT and HuggingFace Transformers with AG News Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79cfafb1-8bf2-4772-a1df-e6c4fb668925",
      "metadata": {
        "scrolled": true,
        "id": "79cfafb1-8bf2-4772-a1df-e6c4fb668925",
        "outputId": "da501700-fa3e-41d5-cd27-0e15618aa3c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 7.7926\n",
            "\n",
            "üìù Original:\n",
            " (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisdiction over alleged crimes in Palestinian territories. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction over alleged crimes committed \"in the occupied Palestinian territory, includin ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìå Summary:\n",
            " The Palestinian Authority becomes the 123rd member of the International Criminal Court on Wednesday. The formal accession was marked with a ceremony at The Hague, in the Netherlands, where the court is based. The Palestinians signed the ICC's founding Rome Statute in January, when they also accepted its jurisdiction.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ‚úÖ Load model and tokenizer\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# ‚úÖ Preprocess function\n",
        "def preprocess_function(examples):\n",
        "    inputs = tokenizer(examples[\"article\"], max_length=512, padding=\"max_length\", truncation=True)\n",
        "    targets = tokenizer(examples[\"highlights\"], max_length=128, padding=\"max_length\", truncation=True)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "\n",
        "    # Replace padding token id with -100 so that it's ignored in loss\n",
        "    inputs[\"labels\"] = [\n",
        "        [(label if label != tokenizer.pad_token_id else -100) for label in labels]\n",
        "        for labels in inputs[\"labels\"]\n",
        "    ]\n",
        "    return inputs\n",
        "\n",
        "# ‚úÖ Load dataset and preprocess\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "dataset[\"train\"] = dataset[\"train\"].select(range(5))  # Use only 5 samples\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# ‚úÖ DataLoader\n",
        "train_loader = DataLoader(tokenized_dataset[\"train\"], batch_size=2, shuffle=True)\n",
        "\n",
        "# ‚úÖ Training setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# ‚úÖ Training loop (1 epoch)\n",
        "model.train()\n",
        "for epoch in range(1):\n",
        "    total_loss = 0\n",
        "    for batch in tqdm(train_loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# ‚úÖ Save model\n",
        "model.save_pretrained(\"./my_bart_summary_model\")\n",
        "tokenizer.save_pretrained(\"./my_bart_summary_model\")\n",
        "\n",
        "# ‚úÖ Inference (summary generation)\n",
        "def summarize(text, model_path=\"./my_bart_summary_model\"):\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\", max_length=512, padding=True, truncation=True).to(device)\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        num_beams=4,\n",
        "        max_length=142,\n",
        "        min_length=56,\n",
        "        length_penalty=2.0,\n",
        "        no_repeat_ngram_size=3,\n",
        "        early_stopping=True,\n",
        "    )\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# ‚úÖ Test summarization on a real sample\n",
        "sample_text = dataset[\"test\"][0][\"article\"]\n",
        "print(\"\\nüìù Original:\\n\", sample_text[:500], \"...\")  # Show partial article\n",
        "print(\"\\nüìå Summary:\\n\", summarize(sample_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40291e46-26cf-48d6-a8a2-1cff70a529cb",
      "metadata": {
        "id": "40291e46-26cf-48d6-a8a2-1cff70a529cb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}