# LLM Practical Experiments

This repository contains the code and resources for 10 practical experiments demonstrating the use of **Large Language Models (LLMs)** in various NLP tasks such as text generation, fine-tuning, summarization, machine translation, multimodal reasoning, reinforcement learning with human feedback (RLHF), and code generation.

These experiments were implemented as part of an academic practical course to understand, explore, and apply LLM techniques effectively.

---

## ğŸ“š Table of Contents
1. [Overview](#overview)
2. [Experiments](#experiments)
3. [Installation](#installation)
4. [Usage](#usage)
5. [Directory Structure](#directory-structure)
---

## ğŸ“– Overview
The repository explores a wide range of LLM concepts and practical tasks:
- Transformer-based text generation
- Domain-specific LLM fine-tuning
- Summarization and translation using LLMs
- Parameter-efficient fine-tuning (PEFT) methods such as **LoRA**
- Multimodal LLMs for image-text question answering
- Prompt engineering for better model guidance
- RLHF to align model outputs with human preferences
- LLM-based code generation and evaluation

Each experiment is implemented in a Jupyter notebook with sections for **Aim, Theory, and Code**.

---

## ğŸ§ª Experiments
| #  | Title |
|----|-------|
| 1  | Transformer-based text generation with hyperparameter tuning |
| 2  | Fine-tune a pre-trained LLM for domain-specific text classification |
| 3  | LLM-based document summarization and evaluation with ROUGE scores |
| 4  | LLM for machine translation between two languages |
| 5  | Parameter-efficient fine-tuning using LoRA or Adapter Layers |
| 6  | Multimodal LLM for image and text-based question answering |
| 7  | Prompt-engineering techniques to optimize LLM responses |
| 8  | RLHF to improve LLM-generated responses |
| 9  | Task-oriented chatbot using LLM |
| 10 | LLM-based code generation and evaluation |

---

## âš™ï¸ Installation
Clone the repository and install the required dependencies:

```bash
git clone https://github.com/<your-username>/LLM-Practical-Experiments.git
cd LLM-Practical-Experiments
```
---
## Usage

Follow the steps provided in each notebook to:

    Load datasets

    Preprocess and tokenize

    Train or fine-tune the model

    Evaluate and analyze results
---
## Directory Structure

```bash
LLM-Practical-Experiments/
â”‚
â”œâ”€â”€ Experiment_1_Transformer_TextGen.ipynb
â”œâ”€â”€ Experiment_2_FineTune_LLM_TextClass.ipynb
â”œâ”€â”€ Experiment_3_Summarization.ipynb
â”œâ”€â”€ Experiment_4_MachineTranslation.ipynb
â”œâ”€â”€ Experiment_5_LoRA_PEFT.ipynb
â”œâ”€â”€ Experiment_6_Multimodal_LLM_ImageQA.ipynb
â”œâ”€â”€ Experiment_7_PromptEngineering.ipynb
â”œâ”€â”€ Experiment_8_RLHF.ipynb
â”œâ”€â”€ Experiment_9_Chatbot.ipynb
â”œâ”€â”€ Experiment_10_CodeGeneration.ipynb
```
---
